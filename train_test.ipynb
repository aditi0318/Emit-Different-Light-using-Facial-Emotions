{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZjimqzZOU7j"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import model_from_json\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# import matplotlib package for plotting purpose\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwPDpQg0OzlW"
      },
      "outputs": [],
      "source": [
        "# Initialize image data generator with rescaling\n",
        "# Normalization\n",
        "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "validation_data_gen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR8h4fMDO88M",
        "outputId": "dbc874ea-8ee6-46af-d137-b2a65e4aef02"
      },
      "outputs": [],
      "source": [
        "# initializing training and testing path\n",
        "train_dir = \"/content/drive/MyDrive/Facial Emotion Recognition/train/\"\n",
        "test_dir = \"/content/drive/MyDrive/Facial Emotion Recognition/test/\"\n",
        "\n",
        "# define function to read and count the number of images into the path for each\n",
        "# class/emotion\n",
        "def count_exp(path, set_):\n",
        "  dict_ = {}\n",
        "  for expression in os.listdir(path):\n",
        "    dir_ = path + expression\n",
        "    dict_[expression] = len(os.listdir(dir_))\n",
        "  df = pd.DataFrame(dict_, index=[set_])\n",
        "  return df\n",
        "\n",
        "# execute the function for counting the images within training set\n",
        "train_count = count_exp(train_dir, 'train')\n",
        "# execute the function for counting the images within test set\n",
        "test_count = count_exp(test_dir, 'test')\n",
        "# print number of images within each class of training set\n",
        "print(train_count)\n",
        "# print number of images within each class of test set\n",
        "print(test_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "bWUVRpnqPM8m",
        "outputId": "5b50818a-44cc-422e-d770-21266823feb5"
      },
      "outputs": [],
      "source": [
        "# plot a bar graph for all classes within training set\n",
        "train_count.transpose().plot(kind='bar')\n",
        "# plot a bar graph for all classes within test set\n",
        "test_count.transpose().plot(kind='bar')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dORfm5GTO1j",
        "outputId": "df7d5193-3346-4e34-ad29-1bee910170db"
      },
      "outputs": [],
      "source": [
        "# Process training data into bacthes of augmented data using the\n",
        "# flow_from_directory function into keras API\n",
        "train_generator = train_data_gen.flow_from_directory(\n",
        "'/content/drive/MyDrive/Facial Emotion Recognition/train/',\n",
        "target_size=(48, 48),\n",
        "batch_size=64,\n",
        "color_mode=\"grayscale\",\n",
        "class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Iz_779TTXlV",
        "outputId": "482bfa53-00ab-49a5-eb5a-9f4500265c8e"
      },
      "outputs": [],
      "source": [
        "# Process test data into bacthes of augmented data using the\n",
        "# flow_from_directory function into keras API\n",
        "validation_generator = validation_data_gen.flow_from_directory(\n",
        "'/content/drive/MyDrive/Facial Emotion Recognition/test',\n",
        "target_size=(48, 48),\n",
        "batch_size=64,\n",
        "color_mode=\"grayscale\",\n",
        "class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX2vqB2MTgyT"
      },
      "outputs": [],
      "source": [
        "# create model structure\n",
        "emotion_model = Sequential()\n",
        "# Block 1\n",
        "# convolutional layer 1\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
        "input_shape=(48, 48, 1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "# Block 2\n",
        "# convolutional layer 2\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "# Block 3\n",
        "# convolutional layer 3\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "emotion_model.compile(loss='categorical_crossentropy',\n",
        "optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53wOgDB6T6UJ",
        "outputId": "8b31a79c-a1f9-47ec-d2ef-34fffad465be"
      },
      "outputs": [],
      "source": [
        "emotion_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsLy-yR-T-gI",
        "outputId": "7d1cb8f4-5e66-490e-a1e4-c30abdc5acd8"
      },
      "outputs": [],
      "source": [
        "# Train the neural network/model\n",
        "emotion_model_info = emotion_model.fit(\n",
        "\n",
        "train_generator,\n",
        "steps_per_epoch=28709 // 64,\n",
        "epochs=5, #reduced epochs\n",
        "validation_data=validation_generator,\n",
        "validation_steps=7178 // 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTfT4P8vUFTb"
      },
      "outputs": [],
      "source": [
        "# Plot the accuracy, validation accuracy, loss and validation loss for training and\n",
        "# test dataset\n",
        "print(emotion_model_info.history.keys())\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(emotion_model_info.history['accuracy'])\n",
        "plt.plot(emotion_model_info.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(emotion_model_info.history['loss'])\n",
        "plt.plot(emotion_model_info.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"modelloss _modelaccuracy.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNPWB7P5URtP"
      },
      "outputs": [],
      "source": [
        "# Print accuracy for training set\n",
        "train_loss, train_accu = emotion_model.evaluate(train_generator)\n",
        "# Print accuracy for test set\n",
        "test_loss, test_accu = emotion_model.evaluate(validation_generator)\n",
        "print(\"final train accuracy = {:.2f}, validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl8EYoVhUV7e"
      },
      "outputs": [],
      "source": [
        "# write model structure in json file\n",
        "model_json = emotion_model.to_json()\n",
        "# use the write method to write our json weights\n",
        "# using with loop to write the file\n",
        "with open(\"emotion_model.json\", \"w\") as json_file:\n",
        "  # write the json file\n",
        "  json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N82bgvjCUcDY"
      },
      "outputs": [],
      "source": [
        "# save trained model weight and the modek in .h5 file\n",
        "emotion_model.save_weights('model_file_30epochs.h5')\n",
        "# emotion_model.save(\"model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4D2VncxUisl"
      },
      "outputs": [],
      "source": [
        " # Confusion Matrix and Classification on training set\n",
        "y_pred = emotion_model.predict(train_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v:k for k,v in class_labels.items()}\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_train = confusion_matrix(train_generator.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_train)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(train_generator.classes, y_pred,\n",
        "target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_train, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)\n",
        "plt.savefig(\"confusion_matrix_train.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZIi1w3_U5TO"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix and Classification on test set\n",
        "y_pred = emotion_model.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v:k for k,v in class_labels.items()}\n",
        "\n",
        "#from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_test = confusion_matrix(validation_generator.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_test)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(validation_generator.classes, y_pred,\n",
        "target_names=target_names))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_test, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)\n",
        "plt.savefig(\"confusion_matrix_test.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
